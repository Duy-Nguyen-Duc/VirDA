{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd0bb512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import (\n",
    "    ResNet18_Weights,\n",
    "    resnet18,\n",
    "    ResNet50_Weights,\n",
    "    resnet50,\n",
    "    ResNet101_Weights,\n",
    "    resnet101,\n",
    ")\n",
    "from pytorch_pretrained_vit import ViT\n",
    "from torch_nn import InstancewiseVisualPromptCoordNet, Classifier, DomainDiscriminator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_backbone(backbone):\n",
    "    if backbone == \"resnet18\":\n",
    "        return resnet18(ResNet18_Weights.IMAGENET1K_V1)\n",
    "    elif backbone == \"resnet50\":\n",
    "        return resnet50(ResNet50_Weights.IMAGENET1K_V1)\n",
    "    elif backbone == \"resnet101\":\n",
    "        return resnet101(ResNet101_Weights.IMAGENET1K_V1)\n",
    "    elif backbone == \"vit_b_32\":\n",
    "        return ViT(\"B_32_imagenet1k\", pretrained=True)\n",
    "    elif backbone == \"vit_b_16\":\n",
    "        return ViT(\"B_16_imagenet1k\", pretrained=True)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported backbone architecture\")\n",
    "\n",
    "def center_crop(x, h_crop, w_crop):\n",
    "    _, _, h, w = x.shape\n",
    "    start_h = (h - h_crop) // 2\n",
    "    start_w = (w - w_crop) // 2\n",
    "    return x[:, :, start_h:start_h+h_crop, start_w:start_w+w_crop]\n",
    "\n",
    "class UModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        backbone=\"vit_b_32\",\n",
    "        hidden_dim=256,\n",
    "        out_dim=65,\n",
    "        imgsize=384, \n",
    "        scaled_factor = [1, 2, 4], \n",
    "        layers = [5, 6, 6], \n",
    "        patch_size = [8, 16, 32]\n",
    "    ):\n",
    "        super(UModel, self).__init__()\n",
    "\n",
    "        self.backbone = get_backbone(backbone)\n",
    "        self.in_dim = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.out_dim = out_dim\n",
    "        self.total_vrs = len(scaled_factor)\n",
    "        self.scaled_factor = scaled_factor\n",
    "\n",
    "        prompts_src, prompts_tgt = [], []\n",
    "        for prompt in (prompts_src, prompts_tgt):\n",
    "            for i in range(self.total_vrs):\n",
    "                prompt.append(\n",
    "                    InstancewiseVisualPromptCoordNet(\n",
    "                        size = imgsize // scaled_factor[i],\n",
    "                        layers=layers[i], \n",
    "                        patch_size=patch_size[i],\n",
    "                        channels=3,\n",
    "                        dropout_p=0.3,\n",
    "                    )\n",
    "                )\n",
    "        self.visual_prompts_src = nn.Sequential(*prompts_src)\n",
    "        self.visual_prompts_tgt = nn.Sequential(*prompts_tgt)\n",
    "\n",
    "        self.classifier_heads_src = Classifier(\n",
    "            in_dim=self.in_dim * self.total_vrs,\n",
    "            hidden_dim=hidden_dim,\n",
    "            out_dim=out_dim,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        self.classifier_head_tgt = Classifier(\n",
    "            in_dim=self.in_dim * self.total_vrs,\n",
    "            hidden_dim=hidden_dim,\n",
    "            out_dim=out_dim,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        self.domain_discriminator = DomainDiscriminator(\n",
    "            in_dim=self.in_dim * self.total_vrs,\n",
    "            hidden_dim=hidden_dim,\n",
    "            out_dim=2,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, vr_branch, head_branch):\n",
    "        prompt = self.visual_prompts_src if vr_branch == \"src\" else self.visual_prompts_tgt\n",
    "        if head_branch == \"src\":\n",
    "            head = self.classifier_heads_src\n",
    "        elif head_branch == \"tgt\":\n",
    "            head = self.classifier_head_tgt\n",
    "        elif head_branch == \"domain\":\n",
    "            head = self.domain_discriminator\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown head branch {head_branch}\")\n",
    "\n",
    "        _, _, h, w = x.shape\n",
    "        feats = []\n",
    "        for i in range(self.total_vrs):\n",
    "            x_crop = center_crop(x, h // self.scaled_factor[i], w // self.scaled_factor[i])\n",
    "            x_prompt = prompt[i](x_crop)\n",
    "            x_up = F.interpolate(x_prompt, size=(h, w), mode=\"bilinear\", align_corners=False)\n",
    "            feats.append(self.backbone(x_up))\n",
    "            \n",
    "        x = torch.cat(feats, dim=1)\n",
    "        return head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dd51fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights.\n"
     ]
    }
   ],
   "source": [
    "from torch_utils import freeze_layers\n",
    "model = UModel()\n",
    "\n",
    "freeze_layers([model.backbone\n",
    "])\n",
    "x = torch.randn(8, 3, 384, 384)\n",
    "\n",
    "out = model(x, \"src\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26b697cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(x, \"src\", \"domain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c692b7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1232, -0.1693],\n",
       "        [-0.1098, -0.0434],\n",
       "        [-0.2516, -0.0437],\n",
       "        [-0.2657,  0.1847],\n",
       "        [-0.2999, -0.0146],\n",
       "        [-0.0594, -0.0322],\n",
       "        [ 0.1343,  0.0299],\n",
       "        [ 0.0841, -0.0184]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
