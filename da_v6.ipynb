{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source data train only\n",
    "from src.data import source_train_loader, source_test_loader, target_train_loader, target_test_loader\n",
    "from src.layers.torch_nn import Classifier\n",
    "\n",
    "from src.layers.utils import freeze_layers\n",
    "from src.eval import evaluate, evaluate_domain_cls\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from src.layers.grl import grad_reverse\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm \n",
    "import os\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "from torchvision.models import ResNet18_Weights, resnet18\n",
    "from src.layers.instance_model import InstancewiseVisualPrompt_v2\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes=10,\n",
    "        imgsize=224,\n",
    "        vr_blocks=2,\n",
    "        attribute_layers=[5,6],\n",
    "        patch_size=[16,32],\n",
    "        attribute_channels=3,\n",
    "    ):\n",
    "        super(BaseClassifier, self).__init__()\n",
    "        self.backbone = resnet18(ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        assert len(attribute_layers) == len(patch_size) == vr_blocks\n",
    "\n",
    "        self.visual_prompt = nn.ModuleList([\n",
    "            InstancewiseVisualPrompt_v2(\n",
    "                imgsize, attribute_layers[idx], patch_size[idx], attribute_channels, dropout_p=0.5\n",
    "        ) for idx in range(vr_blocks)])\n",
    "        self.classifier_head = Classifier(\n",
    "            in_dim=512, hidden_dim=256, out_dim=num_classes, num_res_blocks=2, dropout=0.5\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, output_type=\"logits\"):\n",
    "        for layers in self.visual_prompt:\n",
    "            x = layers(x)\n",
    "        feat = self.backbone(x)\n",
    "\n",
    "        if output_type == \"feat\":\n",
    "            return feat\n",
    "        elif output_type == \"logits\":\n",
    "            return self.classifier_head(feat)\n",
    "        else:\n",
    "            print(f\"Not implemented output type {output_type}\") \n",
    "    \n",
    "    def mc_feature(self, x, mc_samples):\n",
    "        self.train()\n",
    "        B = x.size(0)\n",
    "        D = 512  # resnet18 feature dim\n",
    "        feat_sum = torch.zeros(B, D, device=x.device)\n",
    "        for _ in range(mc_samples):\n",
    "            feat = self.forward(x, output_type=\"feat\")  # dropout on\n",
    "            feat_sum += feat\n",
    "        return feat_sum / mc_samples\n",
    "\n",
    "    def mc_logits(self, x, mc_samples = 4, tau = 1):\n",
    "        self.train()\n",
    "        B = x.size(0)\n",
    "        D = 10  # resnet18 feature dim\n",
    "        p_mean = torch.zeros(B, D, device=x.device)\n",
    "\n",
    "        for _ in range(mc_samples):\n",
    "            logits = self.forward(x, output_type=\"logits\") / tau \n",
    "            p_mean += F.softmax(logits, dim = -1)\n",
    "        \n",
    "        p_mean /= mc_samples\n",
    "        \n",
    "        ent = -(p_mean*(p_mean+1e-8).log()).sum(-1)\n",
    "        return p_mean, ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCDiscriminator_img(nn.Module):\n",
    "    def __init__(self, input_dim, ndf1=256, ndf2=128):\n",
    "        super(FCDiscriminator_img, self).__init__()\n",
    "\n",
    "        self.ln1 = nn.Linear(input_dim, ndf1)\n",
    "        self.ln2 = nn.Linear(ndf1, ndf2)\n",
    "        self.ln3 = nn.Linear(ndf2, ndf2)\n",
    "        self.classifier = nn.Linear(ndf2, 2)\n",
    "\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ln1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.ln2(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.ln3(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duynguyenduc/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "stu_model = BaseClassifier(vr_blocks=1, patch_size=[32], attribute_layers = [6])\n",
    "# teacher model has two VR blocks for both source/target domains\n",
    "tch_model = BaseClassifier(vr_blocks=1, patch_size=[32], attribute_layers = [6])\n",
    "domain_classifier = FCDiscriminator_img(input_dim=512)\n",
    "device = torch.device(\"cuda:0\")\n",
    "ckpt = torch.load(\"checkpoints/best_model_v12.pth\")\n",
    "\n",
    "stu_model.load_state_dict(ckpt)\n",
    "stu_model = stu_model.to(device)\n",
    "tch_model.load_state_dict(ckpt)\n",
    "tch_model =tch_model.to(device)\n",
    "\n",
    "domain_classifier = domain_classifier.to(device)\n",
    "\n",
    "layers = (\n",
    "    [param for name, param in stu_model.named_parameters() if \"visual_prompt\" not in name] +\n",
    "    [param for name, param in tch_model.named_parameters() if \"visual_prompt\" not in name] \n",
    ")\n",
    "\n",
    "optimizer = optim.AdamW(layers, lr=0.01)\n",
    "vr_layers = list(stu_model.visual_prompt.parameters()) + list(tch_model.visual_prompt.parameters()) + list(domain_classifier.parameters())\n",
    "optimizer_vr = optim.AdamW(vr_layers, lr=0.001)\n",
    "criterion_class = nn.CrossEntropyLoss()\n",
    "criterion_domain = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_alpha(u, t_u):\n",
    "    # u: [B], entropy\n",
    "    mask = (u <= t_u).float()\n",
    "    w = torch.exp(-u) * mask\n",
    "    # normalize within batch\n",
    "    return w / (w.sum() + 1e-12) * u.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|                                                             | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████████████████████████████████████████████| 1875/1875 [13:51<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Test Loss Source: 0.4142, Test Accuracy Source: 96.83%\n",
      "Epoch [1/10] Test Loss Target: 11.9818, Test Accuracy Target: 46.14%\n",
      "Epoch [1/10] Test Loss Domain: 0.6932, Test Accuracy Domain: 0.47%\n",
      "Epoch [1]: New best model saved with test accuracy: 96.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████████████████████████████████████████████| 1875/1875 [13:44<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Test Loss Source: 0.4633, Test Accuracy Source: 96.88%\n",
      "Epoch [2/10] Test Loss Target: 17.7915, Test Accuracy Target: 46.29%\n",
      "Epoch [2/10] Test Loss Domain: 0.6932, Test Accuracy Domain: 0.44%\n",
      "Epoch [2]: New best model saved with test accuracy: 96.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████████████████████████████████████████████| 1875/1875 [13:42<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10] Test Loss Source: 0.4553, Test Accuracy Source: 97.13%\n",
      "Epoch [3/10] Test Loss Target: 10.5265, Test Accuracy Target: 50.37%\n",
      "Epoch [3/10] Test Loss Domain: 0.6931, Test Accuracy Domain: 0.54%\n",
      "Epoch [3]: New best model saved with test accuracy: 97.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████████████████████████████████████████████| 1875/1875 [13:32<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10] Test Loss Source: 0.4478, Test Accuracy Source: 96.85%\n",
      "Epoch [4/10] Test Loss Target: 17.6882, Test Accuracy Target: 44.59%\n",
      "Epoch [4/10] Test Loss Domain: 0.6930, Test Accuracy Domain: 0.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████████████████████████████████████████████| 1875/1875 [13:34<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10] Test Loss Source: 0.4047, Test Accuracy Source: 97.34%\n",
      "Epoch [5/10] Test Loss Target: 12.1314, Test Accuracy Target: 53.26%\n",
      "Epoch [5/10] Test Loss Domain: 0.6930, Test Accuracy Domain: 0.54%\n",
      "Epoch [5]: New best model saved with test accuracy: 97.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████████████████████████████████████████████| 1875/1875 [13:35<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10] Test Loss Source: 0.4345, Test Accuracy Source: 97.17%\n",
      "Epoch [6/10] Test Loss Target: 14.9701, Test Accuracy Target: 49.98%\n",
      "Epoch [6/10] Test Loss Domain: 0.6925, Test Accuracy Domain: 0.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████████████████████████████████████████████| 1875/1875 [13:27<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10] Test Loss Source: 0.4042, Test Accuracy Source: 97.35%\n",
      "Epoch [7/10] Test Loss Target: 9.0155, Test Accuracy Target: 57.40%\n",
      "Epoch [7/10] Test Loss Domain: 0.6928, Test Accuracy Domain: 0.81%\n",
      "Epoch [7]: New best model saved with test accuracy: 97.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████████████████████████████████████████████| 1875/1875 [13:29<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10] Test Loss Source: 0.4392, Test Accuracy Source: 97.11%\n",
      "Epoch [8/10] Test Loss Target: 11.2610, Test Accuracy Target: 47.14%\n",
      "Epoch [8/10] Test Loss Domain: 0.6932, Test Accuracy Domain: 0.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████████████████████████████████████████████| 1875/1875 [13:41<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10] Test Loss Source: 0.5238, Test Accuracy Source: 97.11%\n",
      "Epoch [9/10] Test Loss Target: 19.9797, Test Accuracy Target: 44.64%\n",
      "Epoch [9/10] Test Loss Domain: 0.6931, Test Accuracy Domain: 0.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|█████████████████████████████████████████████████| 1875/1875 [13:41<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] Test Loss Source: 0.3570, Test Accuracy Source: 97.70%\n",
      "Epoch [10/10] Test Loss Target: 13.3914, Test Accuracy Target: 54.81%\n",
      "Epoch [10/10] Test Loss Domain: 0.6931, Test Accuracy Domain: 0.62%\n",
      "Epoch [10]: New best model saved with test accuracy: 97.70%\n"
     ]
    }
   ],
   "source": [
    "log_dir = os.path.join(\"runs\", \"da_exp_v12_phase_2\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "mc_samples = 4\n",
    "tau = 0.8\n",
    "t_u = 0.3\n",
    "#training script\n",
    "best_test_acc = 0\n",
    "freeze_layers([stu_model.backbone, tch_model.backbone])\n",
    "total_steps = epochs * len(source_train_loader)\n",
    "for epoch in range(epochs):\n",
    "    tgt_cycle = cycle(target_train_loader)\n",
    "    stu_model.train()\n",
    "    tch_model.train()\n",
    "    domain_classifier.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    pbar = tqdm(source_train_loader, total=len(source_train_loader), desc=f\"Epoch {epoch+1}\", ncols=100)\n",
    "    \n",
    "    for batch_idx, source_data in enumerate(pbar):\n",
    "        pbar.set_description_str(f\"Epoch {epoch+1}\", refresh=True)\n",
    "        target_data = next(tgt_cycle)\n",
    "        current_step = epoch * len(source_train_loader) + batch_idx\n",
    "\n",
    "        src_q_data, src_k_data, src_labels = source_data\n",
    "        tgt_q_data, tgt_k_data, _ = target_data\n",
    "\n",
    "        src_img = src_k_data.to(device)\n",
    "        src_labels = src_labels.to(device)\n",
    "        tgt_img = tgt_k_data.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_vr.zero_grad()\n",
    "\n",
    "        p_s, u_s = tch_model.mc_logits(src_img, mc_samples, tau)\n",
    "        p_t, u_t = stu_model.mc_logits(tgt_img, mc_samples, tau)\n",
    "\n",
    "        loss_cls = criterion_class(p_s, src_labels)\n",
    "        loss_uncertainty = (u_s.mean() - u_t.mean()).pow(2)\n",
    "        del p_s, p_t\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        p = current_step / total_steps\n",
    "        alpha = 2.0 / (1.0 + np.exp(-10 * p)) - 1.0\n",
    "\n",
    "        # Domain loss\n",
    "        f_s = tch_model.mc_feature(src_img, mc_samples)\n",
    "        f_t = stu_model.mc_feature(tgt_img, mc_samples)\n",
    "        f_t_rvs = grad_reverse(f_t, alpha)\n",
    "\n",
    "        alpha_dis_s = compute_alpha(u_s, t_u)\n",
    "        alpha_dis_t = compute_alpha(u_t, t_u)\n",
    "        \n",
    "        domain_src_logits = domain_classifier(f_t.detach())\n",
    "        loss_dis_src_img = criterion_domain(domain_src_logits, torch.zeros(f_t.size(0), dtype=torch.long).to(device)) * alpha_dis_s\n",
    "\n",
    "        domain_tgt_logits = domain_classifier(f_t_rvs.detach())\n",
    "        loss_dis_tgt_img = criterion_domain(domain_tgt_logits, torch.ones(f_t_rvs.size(0), dtype=torch.long).to(device)) * alpha_dis_t\n",
    "\n",
    "        loss_dis = loss_dis_src_img.mean() + loss_dis_tgt_img.mean()\n",
    "        \n",
    "        loss = loss_cls + 0.25*loss_uncertainty + loss_dis\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_vr.step()\n",
    "\n",
    "        # update_ema(tch_model.visual_prompt[0],stu_model.visual_prompt, decay=0.9996)\n",
    "\n",
    "        writer.add_scalar(\"DA/Train Cls loss\", loss_cls.item(), current_step)\n",
    "        writer.add_scalar(\"DA/Train Dis loss\", loss_dis.item(), current_step)\n",
    "        writer.add_scalar(\"DA/Train Unt loss\", loss_uncertainty.item(), current_step)\n",
    "        writer.add_scalar(\"DA/Train BatchLoss\", loss.item(), current_step)\n",
    "\n",
    "    test_loss_src, test_accuracy_src = evaluate(tch_model, test_loader=source_test_loader, device=device)\n",
    "    test_loss_tgt, test_accuracy_tgt = evaluate(tch_model, test_loader=target_test_loader, device=device)\n",
    "    # test_loss_tgt_wo_vr, test_accuracy_tgt_wo_vr = evaluate_wo_vr(tch_model, test_loader=target_test_loader, device=device)\n",
    "    test_loss_domain, test_acc_domain = evaluate_domain_cls(source_test_loader, target_test_loader, tch_model, stu_model, domain_classifier, device)\n",
    "\n",
    "    writer.add_scalar(\"Source/Test EpochLoss\", test_loss_src, epoch)\n",
    "    writer.add_scalar(\"Source/Test Accuracy\", test_accuracy_src, epoch)\n",
    "\n",
    "    writer.add_scalar(\"Target/Test EpochLoss\", test_loss_tgt, epoch)\n",
    "    writer.add_scalar(\"Target/Test Accuracy\", test_accuracy_tgt, epoch)\n",
    "\n",
    "    writer.add_scalar(\"Domain/Test EpochLoss\", test_loss_domain, epoch)\n",
    "    writer.add_scalar(\"Domain/Test Accuracy\", test_acc_domain, epoch)\n",
    "\n",
    "    # writer.add_scalar(\"Target/Test EpochLoss (w/o VR)\", test_loss_tgt_wo_vr, epoch)\n",
    "    # writer.add_scalar(\"Target/Test Accuracy (w/o VR)\", test_accuracy_tgt_wo_vr, epoch)    \n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch + 1}/{epochs}] Test Loss Source: {test_loss_src:.4f}, Test Accuracy Source: {test_accuracy_src:.2f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Epoch [{epoch + 1}/{epochs}] Test Loss Target: {test_loss_tgt:.4f}, Test Accuracy Target: {test_accuracy_tgt:.2f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Epoch [{epoch + 1}/{epochs}] Test Loss Domain: {test_loss_domain:.4f}, Test Accuracy Domain: {test_acc_domain:.2f}%\"\n",
    "    )\n",
    "    # print(\n",
    "    #     f\"Epoch [{epoch + 1}/{epochs}] Test Loss Target (w/o VR): {test_loss_tgt_wo_vr:.4f}, Test Accuracy Target (w/o VR): {test_accuracy_tgt_wo_vr:.2f}%\"\n",
    "    # )\n",
    "\n",
    "    # Save the best model based on test accuracy.\n",
    "    if  test_accuracy_src > best_test_acc:\n",
    "        best_test_acc = test_accuracy_src\n",
    "        best_checkpoint_path = os.path.join(\"checkpoints\", \"best_model_v7_1.pth\")\n",
    "        os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "        torch.save(tch_model.state_dict(), best_checkpoint_path)\n",
    "        print(\n",
    "            f\"Epoch [{epoch + 1}]: New best model saved with test accuracy: {test_accuracy_src:.2f}%\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO:\n",
    "#  [] make a simpler FD dis / move the layer of dis to be same as visual prompt\n",
    "#  [] update training style, following adaptive teacher with branches \n",
    "#  [] log the model's uncertainty ?  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
